{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cb555f3a-2925-438c-adb1-50490602fe4d",
      "metadata": {
        "id": "cb555f3a-2925-438c-adb1-50490602fe4d"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpAUVDZs-wdM",
        "outputId": "989a0744-2e14-4022-c56f-93349750cf22"
      },
      "id": "kpAUVDZs-wdM",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "55de246a-466f-46c1-98f0-9c1f2e187838",
      "metadata": {
        "id": "55de246a-466f-46c1-98f0-9c1f2e187838"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "32f18fdb-ff2a-4926-9d15-7fdc1afebd73",
      "metadata": {
        "id": "32f18fdb-ff2a-4926-9d15-7fdc1afebd73"
      },
      "outputs": [],
      "source": [
        "file = open(\"harry_potter.txt\",\"r\",encoding = \"utf-8\")\n",
        "raw_text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4e6be041-8214-45b5-9ad9-4708670c9917",
      "metadata": {
        "id": "4e6be041-8214-45b5-9ad9-4708670c9917"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "454f5712-c430-476a-aca7-c14452d26c02",
      "metadata": {
        "id": "454f5712-c430-476a-aca7-c14452d26c02"
      },
      "outputs": [],
      "source": [
        "total_tokens = len(tokenizer.encode(raw_text))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nmQZR0d5E2o",
        "outputId": "450e8ccd-ed15-463c-affb-2c460b5d3eaf"
      },
      "id": "-nmQZR0d5E2o",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116725"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f1214cff-4811-4f90-9f19-6d1b88e7b876",
      "metadata": {
        "id": "f1214cff-4811-4f90-9f19-6d1b88e7b876"
      },
      "outputs": [],
      "source": [
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5ca44833-ee71-4c2a-a974-a047a1149bf6",
      "metadata": {
        "id": "5ca44833-ee71-4c2a-a974-a047a1149bf6"
      },
      "outputs": [],
      "source": [
        "def create_dataloader(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c555defd-afbe-4f8b-a155-5ee05a179fe1",
      "metadata": {
        "id": "c555defd-afbe-4f8b-a155-5ee05a179fe1"
      },
      "outputs": [],
      "source": [
        "data = create_dataloader(raw_text, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbORTaMP6JkL",
        "outputId": "fd1b614a-0b1d-4d9d-e072-99f4b752b62a"
      },
      "id": "xbORTaMP6JkL",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 4541,    13,   679,  ...,  8491,   345,   477],\n",
              "         [  198, 22474,   262,  ...,   366,  1858,   338],\n",
              "         [ 1718,   198,   448,  ...,  5166,   286,   198],\n",
              "         [  198,   198,     1,  ...,  1002,   340,   373]]),\n",
              " tensor([[   13,   679,  3521,  ...,   345,   477,   826],\n",
              "         [22474,   262,   691,  ...,  1858,   338,   198],\n",
              "         [  198,   448,   465,  ...,   286,   198, 18855],\n",
              "         [  198,     1,    40,  ...,   340,   373,  3321]])]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3e6b780-f3c4-49ba-8b58-9b99ad4bca00",
      "metadata": {
        "id": "f3e6b780-f3c4-49ba-8b58-9b99ad4bca00"
      },
      "source": [
        "## Self Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c2d63997-be98-401d-8c23-28073d9a860f",
      "metadata": {
        "id": "c2d63997-be98-401d-8c23-28073d9a860f"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_v1(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = x @ self.W_key\n",
        "        queries = x @ self.W_query\n",
        "        values = x @ self.W_value\n",
        "\n",
        "        attn_scores = queries @ keys.T # omega\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "574added-49d7-46d8-a210-adfcb071ef35",
      "metadata": {
        "id": "574added-49d7-46d8-a210-adfcb071ef35"
      },
      "outputs": [],
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        attn_scores = queries @ keys.T\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969a5d08-daee-48db-bbb9-1f9d55fc7482",
      "metadata": {
        "id": "969a5d08-daee-48db-bbb9-1f9d55fc7482"
      },
      "source": [
        "## Causal Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e7536b60-3a07-475a-bdb2-960ee4c3fdfe",
      "metadata": {
        "id": "e7536b60-3a07-475a-bdb2-960ee4c3fdfe"
      },
      "outputs": [],
      "source": [
        "class CausalAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, context_length,\n",
        "                 dropout, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.d_out = d_out\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.dropout = nn.Dropout(dropout) # New\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
        "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
        "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "        attn_weights = self.dropout(attn_weights) # New\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c092c748-e45e-4186-adee-9387a3788f44",
      "metadata": {
        "id": "c092c748-e45e-4186-adee-9387a3788f44"
      },
      "source": [
        "## MultiHead Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "58d28c8b-0132-456d-a72c-85973ad6b4bb",
      "metadata": {
        "id": "58d28c8b-0132-456d-a72c-85973ad6b4bb"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c81f586c-d159-4fea-a923-be90c4abc047",
      "metadata": {
        "id": "c81f586c-d159-4fea-a923-be90c4abc047"
      },
      "source": [
        "## GPT 2 Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "35a9bdd6-dbc1-4373-ba7a-835d4c11b2c7",
      "metadata": {
        "id": "35a9bdd6-dbc1-4373-ba7a-835d4c11b2c7"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": True       # Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "118798fd-f29c-4cf1-a4c5-479fe6d06470",
      "metadata": {
        "id": "118798fd-f29c-4cf1-a4c5-479fe6d06470"
      },
      "source": [
        "## Layer Norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c75aa4aa-29f8-4e95-86bd-55a0c472c7ef",
      "metadata": {
        "id": "c75aa4aa-29f8-4e95-86bd-55a0c472c7ef"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07d2db1a-709d-4e1c-804c-ec13e4cdbd1b",
      "metadata": {
        "id": "07d2db1a-709d-4e1c-804c-ec13e4cdbd1b"
      },
      "source": [
        "## Gelu Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "49c4a17d-8886-4b9e-a771-a6120b99b24e",
      "metadata": {
        "id": "49c4a17d-8886-4b9e-a771-a6120b99b24e"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c79589b7-2378-4401-8fad-e1105277056f",
      "metadata": {
        "id": "c79589b7-2378-4401-8fad-e1105277056f"
      },
      "source": [
        "## FFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "53d07f2d-e932-4039-98fa-6025cdc92bf3",
      "metadata": {
        "id": "53d07f2d-e932-4039-98fa-6025cdc92bf3"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
        "            GELU(), ## Activation\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c47e05ac-4c6e-40b0-bff2-cb0b3b051fe6",
      "metadata": {
        "id": "c47e05ac-4c6e-40b0-bff2-cb0b3b051fe6"
      },
      "source": [
        "## Transformer block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b4ba4f7f-febb-4758-bab9-2879815d747a",
      "metadata": {
        "id": "b4ba4f7f-febb-4758-bab9-2879815d747a"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c2dd9ea-3fc5-41c3-9a9c-0a32ac035eec",
      "metadata": {
        "id": "9c2dd9ea-3fc5-41c3-9a9c-0a32ac035eec"
      },
      "source": [
        "## GPT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a59f6721-6115-4fed-9008-47c3db482831",
      "metadata": {
        "id": "a59f6721-6115-4fed-9008-47c3db482831"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fe853e5d-16ed-4020-a339-bbf3eaecff7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe853e5d-16ed-4020-a339-bbf3eaecff7c",
        "outputId": "cfd100f4-b9d6-48ee-a28e-476ed3e33c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,037,184\n"
          ]
        }
      ],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4cfddc7d-b19f-4baa-8c37-44f0b5d2453b",
      "metadata": {
        "id": "4cfddc7d-b19f-4baa-8c37-44f0b5d2453b"
      },
      "outputs": [],
      "source": [
        "# Train/validation ratio\n",
        "text_data = raw_text\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "73de92c2-9da6-4b93-8580-21c036b02621",
      "metadata": {
        "id": "73de92c2-9da6-4b93-8580-21c036b02621"
      },
      "outputs": [],
      "source": [
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"decrease the `training_ratio`\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4219ad3a-3b67-478d-9e38-46bffb75b04b",
      "metadata": {
        "id": "4219ad3a-3b67-478d-9e38-46bffb75b04b"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8618556a-ed8a-4e00-be6d-ea550018e0d5",
      "metadata": {
        "id": "8618556a-ed8a-4e00-be6d-ea550018e0d5"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d507bd60-2bf4-410f-8936-0aee8b04114a",
      "metadata": {
        "id": "d507bd60-2bf4-410f-8936-0aee8b04114a"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a9b32a8c-c7d0-4595-a8c9-175a1ec666ce",
      "metadata": {
        "id": "a9b32a8c-c7d0-4595-a8c9-175a1ec666ce"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "27652136-389d-42af-9f7e-fcbfe869cc39",
      "metadata": {
        "id": "27652136-389d-42af-9f7e-fcbfe869cc39"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "    ###Input batch:\n",
        " ###tensor([[6109, 3626, 6100,  345],\n",
        "        ##[6109, 1110, 6622,  257]])\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=10, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cc50d2ff-dc12-450b-8486-2d58d93d660e",
      "metadata": {
        "id": "cc50d2ff-dc12-450b-8486-2d58d93d660e"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "EocBt7OXW7Mk"
      },
      "id": "EocBt7OXW7Mk",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IXqS7A5W9I7",
        "outputId": "7dfe0882-4b13-47a6-c802-d5dbd769ebc2"
      },
      "id": "5IXqS7A5W9I7",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-training model using the above dataset"
      ],
      "metadata": {
        "id": "UvzgY-4R9dro"
      },
      "id": "UvzgY-4R9dro"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c1112830-76c8-4abd-889d-6a67725cfd30",
      "metadata": {
        "id": "c1112830-76c8-4abd-889d-6a67725cfd30",
        "outputId": "6b0b44f1-1e35-4d08-a7fd-be6ffb7b66ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.468, Val loss 9.459\n",
            "Ep 1 (Step 000005): Train loss 7.709, Val loss 7.630\n",
            "Ep 1 (Step 000010): Train loss 6.794, Val loss 6.710\n",
            "Ep 1 (Step 000015): Train loss 6.618, Val loss 6.543\n",
            "Ep 1 (Step 000020): Train loss 6.220, Val loss 6.433\n",
            "Ep 1 (Step 000025): Train loss 6.357, Val loss 6.353\n",
            "Ep 1 (Step 000030): Train loss 6.097, Val loss 6.248\n",
            "Ep 1 (Step 000035): Train loss 6.085, Val loss 6.144\n",
            "Ep 1 (Step 000040): Train loss 5.974, Val loss 6.052\n",
            "Ep 1 (Step 000045): Train loss 5.880, Val loss 6.001\n",
            "Ep 1 (Step 000050): Train loss 5.725, Val loss 5.914\n",
            "Every effort moves you,         \n",
            "Ep 2 (Step 000055): Train loss 5.762, Val loss 5.887\n",
            "Ep 2 (Step 000060): Train loss 5.640, Val loss 5.825\n",
            "Ep 2 (Step 000065): Train loss 5.637, Val loss 5.792\n",
            "Ep 2 (Step 000070): Train loss 5.500, Val loss 5.741\n",
            "Ep 2 (Step 000075): Train loss 5.565, Val loss 5.668\n",
            "Ep 2 (Step 000080): Train loss 5.270, Val loss 5.595\n",
            "Ep 2 (Step 000085): Train loss 5.370, Val loss 5.556\n",
            "Ep 2 (Step 000090): Train loss 5.376, Val loss 5.541\n",
            "Ep 2 (Step 000095): Train loss 5.390, Val loss 5.476\n",
            "Ep 2 (Step 000100): Train loss 5.202, Val loss 5.445\n",
            "Every effort moves you          \n",
            "Ep 3 (Step 000105): Train loss 4.923, Val loss 5.417\n",
            "Ep 3 (Step 000110): Train loss 4.896, Val loss 5.402\n",
            "Ep 3 (Step 000115): Train loss 4.983, Val loss 5.383\n",
            "Ep 3 (Step 000120): Train loss 4.737, Val loss 5.373\n",
            "Ep 3 (Step 000125): Train loss 4.489, Val loss 5.350\n",
            "Ep 3 (Step 000130): Train loss 4.657, Val loss 5.333\n",
            "Ep 3 (Step 000135): Train loss 4.639, Val loss 5.326\n",
            "Ep 3 (Step 000140): Train loss 4.626, Val loss 5.316\n",
            "Ep 3 (Step 000145): Train loss 4.381, Val loss 5.275\n",
            "Ep 3 (Step 000150): Train loss 4.478, Val loss 5.279\n",
            "Every effort moves you're not to be in the    \n",
            "Ep 4 (Step 000155): Train loss 4.509, Val loss 5.283\n",
            "Ep 4 (Step 000160): Train loss 4.397, Val loss 5.274\n",
            "Ep 4 (Step 000165): Train loss 4.307, Val loss 5.274\n",
            "Ep 4 (Step 000170): Train loss 4.101, Val loss 5.264\n",
            "Ep 4 (Step 000175): Train loss 4.070, Val loss 5.257\n",
            "Ep 4 (Step 000180): Train loss 4.201, Val loss 5.272\n",
            "Ep 4 (Step 000185): Train loss 4.037, Val loss 5.254\n",
            "Ep 4 (Step 000190): Train loss 3.844, Val loss 5.234\n",
            "Ep 4 (Step 000195): Train loss 3.961, Val loss 5.243\n",
            "Ep 4 (Step 000200): Train loss 3.953, Val loss 5.233\n",
            "Every effort moves you,         \n",
            "Ep 5 (Step 000205): Train loss 3.831, Val loss 5.250\n",
            "Ep 5 (Step 000210): Train loss 3.764, Val loss 5.246\n",
            "Ep 5 (Step 000215): Train loss 3.771, Val loss 5.272\n",
            "Ep 5 (Step 000220): Train loss 3.583, Val loss 5.277\n",
            "Ep 5 (Step 000225): Train loss 3.472, Val loss 5.291\n",
            "Ep 5 (Step 000230): Train loss 3.597, Val loss 5.286\n",
            "Ep 5 (Step 000235): Train loss 3.543, Val loss 5.272\n",
            "Ep 5 (Step 000240): Train loss 3.263, Val loss 5.269\n",
            "Ep 5 (Step 000245): Train loss 3.208, Val loss 5.284\n",
            "Ep 5 (Step 000250): Train loss 3.177, Val loss 5.271\n",
            "Every effort moves you all three-Who's     \n",
            "Ep 6 (Step 000255): Train loss 3.102, Val loss 5.288\n",
            "Ep 6 (Step 000260): Train loss 3.109, Val loss 5.336\n",
            "Ep 6 (Step 000265): Train loss 2.863, Val loss 5.370\n",
            "Ep 6 (Step 000270): Train loss 3.076, Val loss 5.405\n",
            "Ep 6 (Step 000275): Train loss 2.686, Val loss 5.440\n",
            "Ep 6 (Step 000280): Train loss 2.610, Val loss 5.399\n",
            "Ep 6 (Step 000285): Train loss 2.833, Val loss 5.422\n",
            "Ep 6 (Step 000290): Train loss 2.671, Val loss 5.413\n",
            "Ep 6 (Step 000295): Train loss 2.445, Val loss 5.442\n",
            "Ep 6 (Step 000300): Train loss 2.340, Val loss 5.457\n",
            "Ep 6 (Step 000305): Train loss 2.487, Val loss 5.487\n",
            "Every effort moves you       \"Well,\n",
            "Ep 7 (Step 000310): Train loss 2.335, Val loss 5.511\n",
            "Ep 7 (Step 000315): Train loss 2.183, Val loss 5.571\n",
            "Ep 7 (Step 000320): Train loss 2.068, Val loss 5.626\n",
            "Ep 7 (Step 000325): Train loss 1.953, Val loss 5.622\n",
            "Ep 7 (Step 000330): Train loss 1.931, Val loss 5.659\n",
            "Ep 7 (Step 000335): Train loss 1.990, Val loss 5.686\n",
            "Ep 7 (Step 000340): Train loss 1.925, Val loss 5.686\n",
            "Ep 7 (Step 000345): Train loss 1.864, Val loss 5.705\n",
            "Ep 7 (Step 000350): Train loss 1.677, Val loss 5.671\n",
            "Ep 7 (Step 000355): Train loss 1.636, Val loss 5.698\n",
            "Every effort moves you all his eyes. He'd do know, and\n",
            "Ep 8 (Step 000360): Train loss 1.473, Val loss 5.825\n",
            "Ep 8 (Step 000365): Train loss 1.278, Val loss 5.885\n",
            "Ep 8 (Step 000370): Train loss 1.311, Val loss 5.939\n",
            "Ep 8 (Step 000375): Train loss 1.416, Val loss 5.943\n",
            "Ep 8 (Step 000380): Train loss 1.322, Val loss 5.977\n",
            "Ep 8 (Step 000385): Train loss 1.278, Val loss 5.970\n",
            "Ep 8 (Step 000390): Train loss 1.322, Val loss 5.968\n",
            "Ep 8 (Step 000395): Train loss 1.408, Val loss 5.975\n",
            "Ep 8 (Step 000400): Train loss 1.130, Val loss 5.981\n",
            "Ep 8 (Step 000405): Train loss 1.144, Val loss 6.021\n",
            "Every effort moves you, yes, \"I'm not used between classes\n",
            "Ep 9 (Step 000410): Train loss 0.996, Val loss 6.104\n",
            "Ep 9 (Step 000415): Train loss 1.005, Val loss 6.169\n",
            "Ep 9 (Step 000420): Train loss 0.951, Val loss 6.198\n",
            "Ep 9 (Step 000425): Train loss 0.886, Val loss 6.212\n",
            "Ep 9 (Step 000430): Train loss 0.948, Val loss 6.239\n",
            "Ep 9 (Step 000435): Train loss 0.771, Val loss 6.254\n",
            "Ep 9 (Step 000440): Train loss 0.766, Val loss 6.305\n",
            "Ep 9 (Step 000445): Train loss 0.835, Val loss 6.302\n",
            "Ep 9 (Step 000450): Train loss 0.772, Val loss 6.285\n",
            "Ep 9 (Step 000455): Train loss 0.716, Val loss 6.337\n",
            "Every effort moves you had a row! The Bloody    \n",
            "Ep 10 (Step 000460): Train loss 0.702, Val loss 6.387\n",
            "Ep 10 (Step 000465): Train loss 0.696, Val loss 6.471\n",
            "Ep 10 (Step 000470): Train loss 0.646, Val loss 6.475\n",
            "Ep 10 (Step 000475): Train loss 0.569, Val loss 6.579\n",
            "Ep 10 (Step 000480): Train loss 0.567, Val loss 6.497\n",
            "Ep 10 (Step 000485): Train loss 0.523, Val loss 6.548\n",
            "Ep 10 (Step 000490): Train loss 0.643, Val loss 6.461\n",
            "Ep 10 (Step 000495): Train loss 0.493, Val loss 6.567\n",
            "Ep 10 (Step 000500): Train loss 0.413, Val loss 6.561\n",
            "Ep 10 (Step 000505): Train loss 0.465, Val loss 6.559\n",
            "Every effort moves you all   \"But we know, but\n",
            "Training completed in 10.66 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model.state_dict(), 'model_weights.pth')\n"
      ],
      "metadata": {
        "id": "Hcpk_FHlabUZ"
      },
      "id": "Hcpk_FHlabUZ",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a4ecd6f3-5042-483a-a518-a709c6a9224a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ecd6f3-5042-483a-a518-a709c6a9224a",
        "outputId": "b130d1be-7208-4eb3-e235-8ce0fbd7d277"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "164f13b7-23c8-47fe-a3c0-90fbd9250b86",
      "metadata": {
        "id": "164f13b7-23c8-47fe-a3c0-90fbd9250b86"
      },
      "source": [
        "## Top-K sampling and Temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ff9e32af-4a16-4ab5-be30-9653af4a99bf",
      "metadata": {
        "id": "ff9e32af-4a16-4ab5-be30-9653af4a99bf"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context,max_new_tokens,temperature=0.0,top_k=None,eos_id=None):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate(model, encoded, max_new_tokens, context_size, temperature, top_k, eos_id)\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "13b28539-e5cd-4da9-b88e-379c686af44d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13b28539-e5cd-4da9-b88e-379c686af44d",
        "outputId": "4a03b6d2-7250-4212-8d3e-eb33beb109e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you had suff, if my parents and Mrs. Snape?\"  \n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "start_context = \"Every effort moves you\"\n",
        "max_new_tokens = 15\n",
        "temperature = 1.4\n",
        "top_k = 25\n",
        "generate_and_print_sample(model, tokenizer, device, start_context,max_new_tokens,temperature,top_k,eos_id=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd17b26-b8ca-4bb5-aab0-e1fc7d939cc5",
      "metadata": {
        "id": "7bd17b26-b8ca-4bb5-aab0-e1fc7d939cc5"
      },
      "source": [
        "## Loading foundational model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "bb96b8c5-a42a-4c68-8fdc-554fe4d33a57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "4bac1d0273e44446815ed110dbfde30a",
            "c362f057cb64468a95ac93f5d17a42d7",
            "50863b2d3b30421a84b2fc392e8f6e19",
            "d4015ac963f7434393cec436f423c588",
            "6d0d9ccd2d354b08995956ecb49ff7ac",
            "af978edeb78c4857b5ec637512b7e995",
            "23ff7892fcae44058c9fb6bb030bd64d",
            "49fd98fdadeb4e91b47a2b93020cb0ff",
            "c474476aa1c84b17924c3b5f40e3ae06",
            "1f0e3f21b442439cbd7bac6297fa5a0b",
            "2d3eb6e3663a4f70be893243ce836360",
            "a5d958d101a849e99d54a41fceeba0ff",
            "5b8de2db49614614a54af3b222b10ab7",
            "d7e03b52a7034140be54e2afa10072f3",
            "2050e98132a2499791a62cdd80d14564",
            "9e54896d925d40bab75d01d1e389e3fc",
            "430ffa386eaf42f988c48157c15b0450",
            "c8cdaa6dcf9640f6aa95bc879dcfceaa",
            "82b917fff6c048e8bad49eb317920ccf",
            "f9725a5878144ce1b8de967a74842e4e",
            "d41dd05c93d140ea802f3f0e6e76e94f",
            "b144271a856041799a0144e9034ab6f9",
            "7037fcbafe154b95a9ad3d659ba1c396",
            "997025b6b9f64aa79ed37cf907b1d06c",
            "30c0e51f5bce46b9bc215d6c300396ce",
            "7467e133ca8d432c85977d5ab600c1d0",
            "0c947afd52ae43d6971eb574ecfd98d4",
            "0fd0d929239b4c908ed9e49d42647715",
            "47720c6e3e124788a340ba81027df0af",
            "8b43309d3709488e96c2ac5d044b047a",
            "cf378e0492aa46eb8d74ba088581c822",
            "a30ed9c960ab45038846da1f3fa072bd",
            "ccebdb8b0fe24108a749637305a92116"
          ]
        },
        "id": "bb96b8c5-a42a-4c68-8fdc-554fe4d33a57",
        "outputId": "5dbfd936-b040-4c15-9e1b-6c210a15ada5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bac1d0273e44446815ed110dbfde30a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5d958d101a849e99d54a41fceeba0ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7037fcbafe154b95a9ad3d659ba1c396"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "state_dict = model.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e0be1acc-3d98-4afd-895a-3c4b9dd5a20d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0be1acc-3d98-4afd-895a-3c4b9dd5a20d",
        "outputId": "82375d27-1305-45c8-b9ba-b6b1e4e8c8d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 124,439,808\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "cb7f3c09-7b09-4714-a31b-14adb0263c0e",
      "metadata": {
        "id": "cb7f3c09-7b09-4714-a31b-14adb0263c0e"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "fc2037c4-7ba4-4d05-b064-5c242f063c4a",
      "metadata": {
        "id": "fc2037c4-7ba4-4d05-b064-5c242f063c4a"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M[\"qkv_bias\"] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "8e5d7296-f4ed-4a93-b066-60a6ba2c3d37",
      "metadata": {
        "id": "8e5d7296-f4ed-4a93-b066-60a6ba2c3d37"
      },
      "outputs": [],
      "source": [
        "gpt2 =  GPTModel(GPT_CONFIG_124M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "6655fdc7-1510-4cb3-9bee-dcc4e0533c3e",
      "metadata": {
        "id": "6655fdc7-1510-4cb3-9bee-dcc4e0533c3e"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "def load_weights(n_layers,gpt2):\n",
        "    gpt2.tok_emb.weight = assign(gpt2.tok_emb.weight, (state_dict['transformer.wte.weight']))\n",
        "    gpt2.pos_emb.weight = assign(gpt2.pos_emb.weight, (state_dict['transformer.wpe.weight']))\n",
        "    for i in range(n_layers):\n",
        "        gpt2.trf_blocks[i].norm1.scale = assign(gpt2.trf_blocks[i].norm1.scale,(state_dict[f'transformer.h.{i}.ln_1.weight']))\n",
        "        gpt2.trf_blocks[i].norm1.shift = assign(gpt2.trf_blocks[i].norm1.shift,(state_dict[f'transformer.h.{i}.ln_1.bias']))\n",
        "\n",
        "        q_w, k_w, v_w = np.split(state_dict[f'transformer.h.{i}.attn.c_attn.weight'],3,axis=-1)\n",
        "        q_b, k_b, v_b = np.split(state_dict[f'transformer.h.{i}.attn.c_attn.bias'],3,axis=-1)\n",
        "        gpt2.trf_blocks[i].att.W_query.weight = assign(gpt2.trf_blocks[i].att.W_query.weight,(q_w.T))\n",
        "        gpt2.trf_blocks[i].att.W_key.weight = assign(gpt2.trf_blocks[i].att.W_key.weight, (k_w.T))\n",
        "        gpt2.trf_blocks[i].att.W_value.weight = assign(gpt2.trf_blocks[i].att.W_value.weight, (v_w.T))\n",
        "        gpt2.trf_blocks[i].att.W_query.bias = assign(gpt2.trf_blocks[i].att.W_query.bias, (q_b))\n",
        "        gpt2.trf_blocks[i].att.W_key.bias = assign(gpt2.trf_blocks[i].att.W_key.bias, (k_b))\n",
        "        gpt2.trf_blocks[i].att.W_value.bias = assign(gpt2.trf_blocks[i].att.W_value.bias, (v_b))\n",
        "\n",
        "        gpt2.trf_blocks[i].att.out_proj.weight = assign(gpt2.trf_blocks[i].att.out_proj.weight, (state_dict[f'transformer.h.{i}.attn.c_proj.weight']).T)\n",
        "        gpt2.trf_blocks[i].att.out_proj.bias = assign(gpt2.trf_blocks[i].att.out_proj.bias, (state_dict[f'transformer.h.{i}.attn.c_proj.bias']))\n",
        "\n",
        "        gpt2.trf_blocks[i].norm2.scale = assign(gpt2.trf_blocks[i].norm2.scale,(state_dict[f'transformer.h.{i}.ln_2.weight']))\n",
        "        gpt2.trf_blocks[i].norm2.bias = assign(gpt2.trf_blocks[i].norm2.scale,(state_dict[f'transformer.h.{i}.ln_2.bias']))\n",
        "\n",
        "        gpt2.trf_blocks[i].ff.layers[0].weight = assign(gpt2.trf_blocks[i].ff.layers[0].weight,(state_dict[f'transformer.h.{i}.mlp.c_fc.weight'].T))\n",
        "        gpt2.trf_blocks[i].ff.layers[0].bias = assign(gpt2.trf_blocks[i].ff.layers[0].bias,(state_dict[f'transformer.h.{i}.mlp.c_fc.bias']))\n",
        "        gpt2.trf_blocks[i].ff.layers[2].weight = assign(gpt2.trf_blocks[i].ff.layers[2].weight,(state_dict[f'transformer.h.{i}.mlp.c_proj.weight'].T))\n",
        "        gpt2.trf_blocks[i].ff.layers[2].bias = assign(gpt2.trf_blocks[i].ff.layers[2].bias,(state_dict[f'transformer.h.{i}.mlp.c_proj.bias']))\n",
        "\n",
        "    gpt2.final_norm.scale = assign(gpt2.final_norm.scale,(state_dict['transformer.ln_f.weight']))\n",
        "    gpt2.final_norm.shift = assign(gpt2.final_norm.shift,(state_dict['transformer.ln_f.bias']))\n",
        "    gpt2.out_head.weight = assign(gpt2.out_head.weight, (state_dict['lm_head.weight']))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "d8cb0f12-4a4d-4662-9ef0-802642589b93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8cb0f12-4a4d-4662-9ef0-802642589b93",
        "outputId": "6cb08f57-6e46-4800-b61b-2763ca42cd47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-4a7790efd923>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.nn.Parameter(torch.tensor(right))\n"
          ]
        }
      ],
      "source": [
        "load_weights(12,gpt2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "6e652bf6-25d4-4a0d-9168-338816ce1851",
      "metadata": {
        "id": "6e652bf6-25d4-4a0d-9168-338816ce1851"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gpt2.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "6c2ca83e-3563-449e-ab01-96050c470457",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c2ca83e-3563-449e-ab01-96050c470457",
        "outputId": "acb84cba-1606-4656-8492-7ae1597c86a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you are making and moving in a way, moving us to the places it left\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Every effort moves you\"\n",
        "max_new_tokens = 15\n",
        "temperature = 1.2\n",
        "top_k = 25\n",
        "generate_and_print_sample(gpt2, tokenizer, device, start_context,max_new_tokens,temperature,top_k,eos_id=None)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bac1d0273e44446815ed110dbfde30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c362f057cb64468a95ac93f5d17a42d7",
              "IPY_MODEL_50863b2d3b30421a84b2fc392e8f6e19",
              "IPY_MODEL_d4015ac963f7434393cec436f423c588"
            ],
            "layout": "IPY_MODEL_6d0d9ccd2d354b08995956ecb49ff7ac"
          }
        },
        "c362f057cb64468a95ac93f5d17a42d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af978edeb78c4857b5ec637512b7e995",
            "placeholder": "",
            "style": "IPY_MODEL_23ff7892fcae44058c9fb6bb030bd64d",
            "value": "config.json:100%"
          }
        },
        "50863b2d3b30421a84b2fc392e8f6e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49fd98fdadeb4e91b47a2b93020cb0ff",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c474476aa1c84b17924c3b5f40e3ae06",
            "value": 665
          }
        },
        "d4015ac963f7434393cec436f423c588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f0e3f21b442439cbd7bac6297fa5a0b",
            "placeholder": "",
            "style": "IPY_MODEL_2d3eb6e3663a4f70be893243ce836360",
            "value": "665/665[00:00&lt;00:00,20.8kB/s]"
          }
        },
        "6d0d9ccd2d354b08995956ecb49ff7ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af978edeb78c4857b5ec637512b7e995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ff7892fcae44058c9fb6bb030bd64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49fd98fdadeb4e91b47a2b93020cb0ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c474476aa1c84b17924c3b5f40e3ae06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f0e3f21b442439cbd7bac6297fa5a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3eb6e3663a4f70be893243ce836360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d958d101a849e99d54a41fceeba0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b8de2db49614614a54af3b222b10ab7",
              "IPY_MODEL_d7e03b52a7034140be54e2afa10072f3",
              "IPY_MODEL_2050e98132a2499791a62cdd80d14564"
            ],
            "layout": "IPY_MODEL_9e54896d925d40bab75d01d1e389e3fc"
          }
        },
        "5b8de2db49614614a54af3b222b10ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_430ffa386eaf42f988c48157c15b0450",
            "placeholder": "",
            "style": "IPY_MODEL_c8cdaa6dcf9640f6aa95bc879dcfceaa",
            "value": "model.safetensors:100%"
          }
        },
        "d7e03b52a7034140be54e2afa10072f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b917fff6c048e8bad49eb317920ccf",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9725a5878144ce1b8de967a74842e4e",
            "value": 548105171
          }
        },
        "2050e98132a2499791a62cdd80d14564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d41dd05c93d140ea802f3f0e6e76e94f",
            "placeholder": "",
            "style": "IPY_MODEL_b144271a856041799a0144e9034ab6f9",
            "value": "548M/548M[00:12&lt;00:00,57.3MB/s]"
          }
        },
        "9e54896d925d40bab75d01d1e389e3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "430ffa386eaf42f988c48157c15b0450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cdaa6dcf9640f6aa95bc879dcfceaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82b917fff6c048e8bad49eb317920ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9725a5878144ce1b8de967a74842e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d41dd05c93d140ea802f3f0e6e76e94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b144271a856041799a0144e9034ab6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7037fcbafe154b95a9ad3d659ba1c396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_997025b6b9f64aa79ed37cf907b1d06c",
              "IPY_MODEL_30c0e51f5bce46b9bc215d6c300396ce",
              "IPY_MODEL_7467e133ca8d432c85977d5ab600c1d0"
            ],
            "layout": "IPY_MODEL_0c947afd52ae43d6971eb574ecfd98d4"
          }
        },
        "997025b6b9f64aa79ed37cf907b1d06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fd0d929239b4c908ed9e49d42647715",
            "placeholder": "",
            "style": "IPY_MODEL_47720c6e3e124788a340ba81027df0af",
            "value": "generation_config.json:100%"
          }
        },
        "30c0e51f5bce46b9bc215d6c300396ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b43309d3709488e96c2ac5d044b047a",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf378e0492aa46eb8d74ba088581c822",
            "value": 124
          }
        },
        "7467e133ca8d432c85977d5ab600c1d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a30ed9c960ab45038846da1f3fa072bd",
            "placeholder": "",
            "style": "IPY_MODEL_ccebdb8b0fe24108a749637305a92116",
            "value": "124/124[00:00&lt;00:00,12.6kB/s]"
          }
        },
        "0c947afd52ae43d6971eb574ecfd98d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd0d929239b4c908ed9e49d42647715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47720c6e3e124788a340ba81027df0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b43309d3709488e96c2ac5d044b047a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf378e0492aa46eb8d74ba088581c822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a30ed9c960ab45038846da1f3fa072bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccebdb8b0fe24108a749637305a92116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}